{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aca9344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from operator import add\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3948535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatStop(BaseModel):\n",
    "    decision: Literal[\"stop\", \"keep_going\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90a2616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BotState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    decision: Literal[\"stop\", \"keep_going\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b97bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model= \"gemini-2.5-flash-lite\")\n",
    "def chatbot(state: BotState):\n",
    "    res = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [res]}\n",
    "\n",
    "def check(state: BotState) -> Literal[\"stop\", \"keep_going\"]:\n",
    "    decision = state[\"messages\"][-1].content\n",
    "    if decision == \"stop\":\n",
    "        return \"stop\"\n",
    "    return \"keep_going\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0309c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 43.960479692s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\n",
      "Please retry in 41.771932944s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhey tehre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2138\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2295\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   2294\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m2295\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:269\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    266\u001b[39m params = {\n\u001b[32m    267\u001b[39m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service\n\u001b[32m    268\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "llm.invoke(\"hey tehre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH\n",
    "graph = StateGraph(BotState)\n",
    "\n",
    "graph.add_node(\"bot\", chatbot)\n",
    "\n",
    "graph.add_edge(START, \"bot\")\n",
    "graph.add_conditional_edges(\"bot\", check, {\"stop\": END, \"keep_going\": \"bot\"})\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7442635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000002D91B7ACCD0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4441b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 27.990575973s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 25.578767149s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 21.154066965s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m final_state = \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhii, my name is\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeep_going\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mchatbot\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchatbot\u001b[39m(state: BotState):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     res = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [res]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2138\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2295\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   2294\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m2295\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:269\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    266\u001b[39m params = {\n\u001b[32m    267\u001b[39m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service\n\u001b[32m    268\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GyanPrakashKuswaha\\GenAI\\yt-chatbot\\.venv\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "final_state = workflow.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"hii, my name is\")],\n",
    "    \"decision\": \"keep_going\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 3.625173764s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 1.184412269s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 56.75090392s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 48.291301436s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "].\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class BotState(TypedDict):\n",
    "    # 'add_messages' handles appending new messages to the existing list automatically\n",
    "    messages: Annotated[list[BaseMessage], add_messages] \n",
    "\n",
    "# 1. Update Model Name (Assuming 1.5-flash, adjust if you have specific access)\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\")\n",
    "\n",
    "def chatbot(state: BotState):\n",
    "    # 2. FIX: Pass the list of messages directly, not a dict\n",
    "    res = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [res]}\n",
    "\n",
    "def check(state: BotState) -> Literal[\"stop\", \"keep_going\"]:\n",
    "    # Warning: The LLM is unlikely to output exactly \"stop\" unless instructed.\n",
    "    # This logic might loop until it hits the recursion limit.\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    if \"bye\" in last_message.lower() or \"stop\" in last_message.lower():\n",
    "        return \"stop\"\n",
    "    return \"keep_going\"\n",
    "\n",
    "# GRAPH\n",
    "graph = StateGraph(BotState)\n",
    "\n",
    "graph.add_node(\"bot\", chatbot)\n",
    "\n",
    "graph.add_edge(START, \"bot\")\n",
    "\n",
    "# 3. FIX: Only use conditional edges here. \n",
    "# You previously had graph.add_edge(\"bot\", END) as well, which conflicts.\n",
    "graph.add_conditional_edges(\n",
    "    \"bot\", \n",
    "    check, \n",
    "    {\"stop\": END, \"keep_going\": \"bot\"}\n",
    ")\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Invoke\n",
    "final_state = workflow.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"hii, my name is\")],\n",
    "})\n",
    "\n",
    "# Print result to verify\n",
    "print(final_state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
